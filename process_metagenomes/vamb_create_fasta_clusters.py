"""
Create fasta files from the clusters generated by Vamb. This does not require
the vamb toolkit.

"""

import os
import sys
import gzip
import argparse

__author__ = 'Rob Edwards'



def stream_fasta(fastafile, whole_id=True):
    """
    Stream a fasta file, one read at a time. Saves memory!

    :param fastafile: The fasta file to stream
    :type fastafile: str
    :param whole_id: Whether to return the whole id (default) or just up to the first white space
    :type whole_id:bool
    :return:A single read
    :rtype:str, str
    """

    try:
        if fastafile.endswith('.gz'):
            f = gzip.open(fastafile, 'rt')
        else:
            f = open(fastafile, 'r')
    except IOError as e:
        sys.stderr.write(str(e) + "\n")
        sys.stderr.write("Message: \n" + str(e.message) + "\n")
        sys.exit("Unable to open file " + fastafile)

    posn = 0
    while f:
        # first line should start with >
        idline = f.readline()
        if not idline:
            break
        if not idline.startswith('>'):
            sys.exit("Do not have a fasta file at: {}".format(idline))
        if not whole_id:
            idline = idline.split(" ")[0]
        idline = idline.strip().replace('>', '', 1)
        posn = f.tell()
        line = f.readline()
        seq = ""
        while not line.startswith('>'):
            seq += line.strip()
            posn = f.tell()
            line = f.readline()
            if not line:
                break
        f.seek(posn)
        yield idline, seq


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description=' ')
    parser.add_argument('-f', help='fasta file', required=True)
    parser.add_argument('-o', help='output directory', required=True)
    parser.add_argument('-c', help='cluster file', required=True)
    parser.add_argument('-m', type=int, default=0,
                        help='minimum length of cluster to keep (bp). Note this requires two passes of the fasta file')
    parser.add_argument('-v', help='verbose output', action='store_true')
    args = parser.parse_args()

    # Read the cluster file
    clusters = {}
    with open(args.c) as f:
        for line in f:
            if line.startswith('#'):
                continue
            if line.startswith('clustername'):
                continue
            parts = line.strip().split('\t')
            cluster_id = parts[0]
            contig_id = parts[1]
            clusters[contig_id] = cluster_id

    cluster_lengths = {x: 0 for x in set(clusters.values())}
    if args.m:
        # we need to read the fasta file and store the length of each contig
        for header, seq in stream_fasta(args.f):
            cluster_lengths[clusters[header]] += len(seq)
        # now we only keep the clusters that are longer than the minimum length
        clusters = {k: v for k, v in clusters.items() if cluster_lengths[v] >= args.m}

    os.makedirs(args.o, exist_ok=True)
    filehandles = {}
    # now we stream the fasta file and write the contigs to the appropriate file, and save the filehandle in filehandles
    # then when we are done we close the filehandles
    for header, seq in stream_fasta(args.f):
        if header not in clusters:
            continue
        cluster_id = clusters[header]
        if cluster_id not in filehandles:
            filename = os.path.join(args.o, f'{cluster_id}.fasta')
            filehandles[cluster_id] = open(filename, 'w')
        print(f">{header}\n{seq}", file=filehandles[cluster_id])

    for handle in filehandles.values():
        handle.close()